import torch
import torch.nn as nn
from utils import sparse_dropout, spmm
class ANAGL(nn.Module):
    def __init__(self, n_u, n_i, n_u_A, n_i_A, d, u_mul_s, v_mul_s, u_mul_s_A, v_mul_s_A, ut, vt, ut_A, vt_A, train_csr, train_csr_A, adj_norm, \
                adj_norm_A, l, temp, lambda_1, lambda_2, lambda_3, dropout, batch_user):
        self.E_u_0 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(n_u,d)))
        self.E_i_0 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(n_i,d)))
        self.train_csr = train_csr
        self.adj_norm = adj_norm
        self.l = l
        self.E_u_list = [None] * (l+1)
        self.E_i_list = [None] * (l+1)
        self.E_u_list[0] = self.E_u_0
        self.E_i_list[0] = self.E_i_0
        self.Z_u_list = [None] * (l+1)
        self.Z_i_list = [None] * (l+1)
        self.G_u_list = [None] * (l+1)
        self.G_i_list = [None] * (l+1)
        self.temp = temp
        self.lambda_1 = lambda_1
        self.lambda_2 = lambda_2
        self.lambda_3 = lambda_3
        self.dropout = dropout
        self.act = nn.LeakyReLU(0.5)
        self.batch_user = batch_user
        self.Ws = nn.ModuleList([W_contrastive(d) for i in range(l)])
        self.E_u = None
        self.E_i = None
        self.u_mul_s = u_mul_s
        self.v_mul_s = v_mul_s
        self.ut = ut
        self.vt = vt
        self.E_u_0_A = nn.Parameter(nn.init.xavier_uniform_(torch.empty(n_u_A,d)))
        self.E_i_0_A = nn.Parameter(nn.init.xavier_uniform_(torch.empty(n_i_A,d)))
        self.adj_norm_A = adj_norm_A
        self.E_u_list_A = [None] * (l+1)
        self.E_i_list_A = [None] * (l+1)
        self.E_u_list_A[0] = self.E_u_0_A
        self.E_i_list_A[0] = self.E_i_0_A
        self.Z_u_list_A = [None] * (l+1)
        self.Z_i_list_A = [None] * (l+1)
        self.G_u_list_A = [None] * (l+1)
        self.G_i_list_A = [None] * (l+1)
        self.E_u_A = None
        self.E_i_A = None
        self.u_mul_s_A = u_mul_s_A 
        self.v_mul_s_A = v_mul_s_A
        self.ut_A = ut_A
        self.vt_A = vt_A
        self.train_csr_A = train_csr_A
        
    def forward_CL(self, uids, iids, uids_A, iids_A, pos, neg):
       
        for layer in range(1, self.l + 1):
                self.Z_u_list[layer] = self.act(spmm(sparse_dropout(self.adj_norm,self.dropout), self.E_i_list[layer-1]))
                self.Z_i_list[layer] = self.act(spmm(sparse_dropout(self.adj_norm,self.dropout).transpose(0,1), self.E_u_list[layer-1]))
    
                self.Z_u_list_A[layer] = self.act(spmm(sparse_dropout(self.adj_norm_A, self.dropout), self.E_i_list_A[layer-1]))
                self.Z_i_list_A[layer] = self.act(spmm(sparse_dropout(self.adj_norm_A, self.dropout).transpose(0,1), self.E_u_list_A[layer-1]))

            
                vt_ei = self.vt @ self.E_i_list[layer-1]
                self.G_u_list[layer] = self.act(self.u_mul_s @ vt_ei)
                ut_eu = self.ut @ self.E_u_list[layer-1]
                self.G_i_list[layer] = self.act(self.v_mul_s @ ut_eu)

                vt_ei_A = self.vt_A @ self.E_i_list_A[layer-1]
                self.G_u_list_A[layer] = self.act(self.u_mul_s_A @ vt_ei_A)
                ut_eu_A = self.ut_A @ self.E_u_list_A[layer-1]
                self.G_i_list_A[layer] = self.act(self.v_mul_s_A @ ut_eu_A)
                
                
                self.E_u_list[layer] = self.Z_u_list[layer] + self.E_u_list[layer-1]
                self.E_i_list[layer] = self.Z_i_list[layer] + self.E_i_list[layer-1]
                
                self.E_u_list_A[layer] = self.Z_u_list_A[layer] + self.E_u_list_A[layer-1]
                self.E_i_list_A[layer] = self.Z_i_list_A[layer] + self.E_i_list_A[layer-1]
                
                
        self.E_u = sum(self.E_u_list)
        self.E_i = sum(self.E_i_list)
            
        self.E_u_A = sum(self.E_u_list_A)
        self.E_i_A = sum(self.E_i_list_A)
            

        loss_s_1 = 0
        for l in range(1,self.l+1):
                u_mask = (torch.rand(len(uids))>0.5).float().cuda()

                gnn_u = nn.functional.normalize(self.Z_u_list[l][uids],p=2,dim=1)
                hyper_u = nn.functional.normalize(self.G_u_list[l][uids],p=2,dim=1)
                hyper_u = self.Ws[l-1](hyper_u)
                pos_score = torch.exp((gnn_u*hyper_u).sum(1)/self.temp)
                neg_score = torch.exp(gnn_u @ hyper_u.T/self.temp).sum(1)
                loss_s_u = ((-1 * torch.log(pos_score/(neg_score+1e-8) + 1e-8))*u_mask).sum()
                loss_s_1 = loss_s_1 + loss_s_u

                i_mask = (torch.rand(len(iids))>0.5).float().cuda()

                gnn_i = nn.functional.normalize(self.Z_i_list[l][iids],p=2,dim=1)
                hyper_i = nn.functional.normalize(self.G_i_list[l][iids],p=2,dim=1)
                hyper_i = self.Ws[l-1](hyper_i)
                pos_score = torch.exp((gnn_i*hyper_i).sum(1)/self.temp)
                neg_score = torch.exp(gnn_i @ hyper_i.T/self.temp).sum(1)
                loss_s_i = ((-1 * torch.log(pos_score/(neg_score+1e-8) + 1e-8))*i_mask).sum()
                loss_s_1 = loss_s_1 + loss_s_i          
            
        loss_s_A = 0
        for l in range(1, self.l + 1):
                u_mask_A = (torch.rand(len(uids_A)) > 0.5).float().cuda()
                gnn_u_A = nn.functional.normalize(self.Z_u_list_A[l][uids_A], p=2, dim=1)
                hyper_u_A = nn.functional.normalize(self.G_u_list_A[l][uids_A], p=2, dim=1)
                hyper_u_A = self.Ws[l-1](hyper_u_A)
                pos_score_A = torch.exp((gnn_u_A * hyper_u_A).sum(1)/self.temp)
                neg_score_A = torch.exp(gnn_u_A @ hyper_u_A.T / self.temp).sum(1)
                loss_s_u_A = ((-1 * torch.log(pos_score_A / (neg_score_A + 1e-8) + 1e-8))*u_mask_A).sum()
                loss_s_A = loss_s_A + loss_s_u_A
                
                i_mask_A= (torch.rand(len(iids_A))>0.5).float().cuda()
                gnn_i_A = nn.functional.normalize(self.Z_i_list_A[l][iids],p=2,dim=1)
                hyper_i_A = nn.functional.normalize(self.G_i_list_A[l][iids],p=2,dim=1)
                hyper_i_A = self.Ws[l-1](hyper_i_A)
                pos_score_A = torch.exp((gnn_i_A * hyper_i_A).sum(1)/self.temp)
                neg_score_A = torch.exp(gnn_i_A @ hyper_i_A.T/self.temp).sum(1)
                loss_s_i_A = ((-1 * torch.log(pos_score_A /(neg_score_A + 1e-8) + 1e-8))*i_mask_A).sum()
                loss_s_A = loss_s_A + loss_s_i_A

        loss_s_user = 0
        for l in range(1, self.l + 1):
                u_mask = (torch.rand(len(uids)) > 0.5).float().cuda()
                gnn_u = nn.functional.normalize(self.Z_u_list[l][uids], p=2, dim=1)
                hyper_u = nn.functional.normalize(self.G_u_list[l][uids], p=2, dim=1)
                hyper_u = self.Ws[l-1](hyper_u)
                u_mask_A = (torch.rand(len(uids_A)) > 0.5).float().cuda()
                gnn_u_A = nn.functional.normalize(self.Z_u_list_A[l][uids_A], p=2, dim=1)
                hyper_u_A = nn.functional.normalize(self.G_u_list_A[l][uids_A], p=2, dim=1)
                hyper_u_A = self.Ws[l-1](hyper_u_A)


                pos_score = torch.exp((gnn_u * hyper_u_A).sum(1)/self.temp)
                neg_score = torch.exp(gnn_u @ hyper_u_A.T /self.temp).sum(1)
                loss_s_u = ((-1 * torch.log(pos_score/(neg_score + 1e-8) + 1e-8))*u_mask).sum()
                loss_s_user = loss_s_user + loss_s_u

        loss_r = 0
        for i in range(len(uids)):
                u = uids[i]
                u_emb = self.E_u[u]
                u_pos = pos[i]
                u_neg = neg[i]
                pos_emb = self.E_i[u_pos]
                neg_emb = self.E_i[u_neg]
                pos_scores = u_emb @ pos_emb.T
                neg_scores = u_emb @ neg_emb.T
                bpr = nn.functional.relu(1-pos_scores+neg_scores)
                loss_r = loss_r + bpr.sum()
        loss_r = loss_r/self.batch_user
        # total loss
        loss_s = loss_s_A + loss_s_1 + loss_s_user
       
        loss = loss_r     
        return loss, loss_r, loss_s
  
    def predict(self, uids):
        preds = self.E_u[uids] @ self.E_i.T 
        mask = self.train_csr[uids.cpu().numpy()].toarray()
        mask = torch.Tensor(mask).cuda()
        preds = preds * (1-mask)
        predictions = preds.argsort(descending=True)
        return predictions
